<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alexis Cook</title>
    <description>Deep Learning Professional</description>
    <link>http://localhost:4000//</link>
    <atom:link href="http://localhost:4000//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 08 Apr 2017 23:40:33 -0500</pubDate>
    <lastBuildDate>Sat, 08 Apr 2017 23:40:33 -0500</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Using Transfer Learning to Classify Images with Keras</title>
        <description>&lt;p&gt;In this blog post, I will teach you how to &lt;em&gt;efficiently&lt;/em&gt; use deep learning to train an algorithm to perform object classification.  This blog post is inspired by a &lt;a href=&quot;https://medium.com/@st553/using-transfer-learning-to-classify-images-with-tensorflow-b0f3142b9366&quot;&gt;recent Medium post&lt;/a&gt; that made use of Tensorflow.  I will adapt the code to Keras (version 2.0.2), and all code will be written in Python 3.5.&lt;/p&gt;

&lt;p&gt;I will assume that you are already familiar with the ideas behind convolutional neural networks (CNNs) and transfer learning and will focus on discussing the details of my code in Keras.&lt;/p&gt;

&lt;p&gt;If you need to learn more about CNNs, I recommend reading the notes for the &lt;a href=&quot;http://cs231n.github.io/convolutional-networks/&quot;&gt;CS231n&lt;/a&gt; course at Stanford.  All lectures are also available &lt;a href=&quot;https://www.youtube.com/watch?v=LxfUGhug-iQ&amp;amp;list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&amp;amp;index=7&quot;&gt;online&lt;/a&gt;.  You are also encouraged to check out Term 2 of Udacity’s &lt;a href=&quot;https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889&quot;&gt;Artificial Intelligence Nanodegree&lt;/a&gt;, where you can find a comprehensive introduction to neural networks (NNs), CNNs (including transfer learning), and recurrent neural networks (RNNs).&lt;/p&gt;

&lt;h4 id=&quot;the-dataset&quot;&gt;The Dataset&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~kriz/cifar.html&quot;&gt;CIFAR-10&lt;/a&gt; is a popular dataset composed of 60,000 tiny color images that each depict an object from one of ten different categories.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/cifar10.png&quot; alt=&quot;cifar-10 dataset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This dataset is simple to load in Keras.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cifar10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In fact, there are many &lt;a href=&quot;https://keras.io/datasets/&quot;&gt;other datasets&lt;/a&gt; that can easily be imported in Keras.&lt;/p&gt;

&lt;h4 id=&quot;extracting-the-inceptionv3-bottleneck-features&quot;&gt;Extracting the InceptionV3 Bottleneck Features&lt;/h4&gt;

&lt;p&gt;We won’t build or train our own CNNs.  Instead, we will use &lt;strong&gt;transfer learning&lt;/strong&gt; to leverage a pre-trained CNN that has demonstrated state-of-the-art performance in object classification tasks.&lt;/p&gt;

&lt;p&gt;Keras makes it very easy to access several pre-trained &lt;a href=&quot;https://keras.io/applications/&quot;&gt;CNN architectures&lt;/a&gt;.  For now, we will focus on the InceptionV3 architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/inception.png&quot; alt=&quot;inception architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After importing the necessary Python class, it’s only one line of code to get the model, along with the corresponding weights.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.applications.inception_v3&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InceptionV3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InceptionV3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'imagenet'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;include_top&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The pre-trained InceptionV3 architecture is now stored in the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;base_model&lt;/code&gt;.  The final layer of this network is a densely connected layer designed to distinguish between the &lt;a href=&quot;https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a&quot;&gt;1000 different object categories&lt;/a&gt; in the ImageNet database.  We will remove this final layer and save the resultant network in a new model.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'avg_pool'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This new model will no longer return a predicted image class, since the classification layer has been removed; however, the CNN now stored in &lt;code class=&quot;highlighter-rouge&quot;&gt;model&lt;/code&gt; still provides us with a useful way to extract features from images.  By passing each of the CIFAR-10 images through this model, we can convert each image from its 32x32x3 array of raw image pixels to a vector with 2048 entries.  We’ll refer to this dataset of 2048-dimensional points as InceptionV3 bottleneck features.&lt;/p&gt;

&lt;h4 id=&quot;using-t-sne-to-visualize-bottleneck-features&quot;&gt;Using t-SNE to Visualize Bottleneck Features&lt;/h4&gt;

&lt;p&gt;Towards visualizing the bottleneck features, we will use a dimensionality reduction technique called &lt;a href=&quot;http://distill.pub/2016/misread-tsne/&quot;&gt;t-SNE&lt;/a&gt; (aka t-Distributed Stochastic Neighbor Embedding).  We use t-SNE to reduce the dimensionality of each point, in a way where the points in the lower-dimensional space preserve the pointwise distances from the original, higher-dimensional space.  Scikit-learn &lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html&quot;&gt;has an implementation&lt;/a&gt; of t-SNE, but it is too slow for our purposes.  Instead, to work with our very large, highly dimensional dataset, you’ll need to work with a faster implementation.  The implementation we encourage you to use can be found &lt;a href=&quot;https://github.com/alexisbcook/tsne&quot;&gt;on github&lt;/a&gt;, and can be installed by running &lt;code class=&quot;highlighter-rouge&quot;&gt;pip install git+https://github.com/alexisbcook/tsne.git&lt;/code&gt; in the terminal.&lt;/p&gt;

&lt;p&gt;After plotting the resulting 2-dimensional points, color-coded by label, we get the plot below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/tsne.png&quot; alt=&quot;t-sne plot for transfer learning on cifar-10&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It looks like InceptionV3 has done an amazing job with teasing out the content in the image, where points containing similar objects are mostly confined to nearby regions in the 2D plot.&lt;/p&gt;

&lt;h4 id=&quot;performing-classification-with-transfer-learning&quot;&gt;Performing Classification with Transfer Learning&lt;/h4&gt;

&lt;p&gt;When we train a very shallow NN on the bottleneck features, we attain a test accuracy of 80 percent!  That’s amazing! :)&lt;/p&gt;

&lt;h4 id=&quot;play-with-the-code&quot;&gt;Play with the Code!&lt;/h4&gt;

&lt;p&gt;Can we do better with other pre-trained architectures?  Feel free to download the code on Github and try your own hand at transfer learning!  &lt;strong&gt;Link to repository coming soon ~&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Apr 2016 06:39:23 -0500</pubDate>
        <link>http://localhost:4000//2016/using-transfer-learning-to-classify-images-with-keras/</link>
        <guid isPermaLink="true">http://localhost:4000//2016/using-transfer-learning-to-classify-images-with-keras/</guid>
        
        <category>transfer-learning</category>
        
        <category>keras</category>
        
        
        <category>keras</category>
        
      </item>
    
  </channel>
</rss>
